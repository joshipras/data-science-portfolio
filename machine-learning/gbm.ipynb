{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from IPython.display import HTML\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n",
    "from sklearn.metrics import mean_squared_error, r2_score,classification_report, confusion_matrix, roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Gradient Boosting Trees using Python </h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Introduction </h2>\n",
    "<br>\n",
    "\n",
    "<li> Boosting algorithms are a family of machine learning algorithms that combine \"weak learners\" to form a \"strong learner\". A weak learner is any machine learning algorithm that has better accuracy than simply guessing, but only performs well on a subset of the data. Boosting works by using these to solve subsections of the problem, by peeling them away so future boosting iterations can solve the remaining sections.\n",
    "\n",
    "<li> For instance, an algorithm classifying animals at a zoo only classifies zebras correctly, most of the time, and simply guesses for other animals. Boosting involves using the model for zebras while other weak learners to focus on the remaining animals.\n",
    "    \n",
    "<li> In the case of Gradient Boosting Trees, Decision Trees are the weak learners.  \n",
    "    \n",
    "<h2> Gradient Boosting Regression </h2>\n",
    "    \n",
    "<li> For Regression, \n",
    "      1. each possible split of the tree is examined. I.e. the data is split around each value in the dataset. \n",
    "      2. The split is selected so that values closest to each other are clumped together (i.e Sum of Squared errors of Split Value and each datapoint) is minimized.\n",
    "      3. The average error in the 2 subsets is added to all values in the group.\n",
    "      4. The process is repeated until a certain depth is reached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_data = pd.read_csv(\"OnlineNewsPopularity.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_data.columns = news_data.columns.str.lstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timedelta</th>\n",
       "      <th>n_tokens_title</th>\n",
       "      <th>n_tokens_content</th>\n",
       "      <th>n_unique_tokens</th>\n",
       "      <th>n_non_stop_words</th>\n",
       "      <th>n_non_stop_unique_tokens</th>\n",
       "      <th>num_hrefs</th>\n",
       "      <th>num_self_hrefs</th>\n",
       "      <th>num_imgs</th>\n",
       "      <th>num_videos</th>\n",
       "      <th>...</th>\n",
       "      <th>min_positive_polarity</th>\n",
       "      <th>max_positive_polarity</th>\n",
       "      <th>avg_negative_polarity</th>\n",
       "      <th>min_negative_polarity</th>\n",
       "      <th>max_negative_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <th>abs_title_subjectivity</th>\n",
       "      <th>abs_title_sentiment_polarity</th>\n",
       "      <th>shares</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>354.530471</td>\n",
       "      <td>10.398749</td>\n",
       "      <td>546.514731</td>\n",
       "      <td>0.548216</td>\n",
       "      <td>0.996469</td>\n",
       "      <td>0.689175</td>\n",
       "      <td>10.883690</td>\n",
       "      <td>3.293638</td>\n",
       "      <td>4.544143</td>\n",
       "      <td>1.249874</td>\n",
       "      <td>...</td>\n",
       "      <td>0.095446</td>\n",
       "      <td>0.756728</td>\n",
       "      <td>-0.259524</td>\n",
       "      <td>-0.521944</td>\n",
       "      <td>-0.107500</td>\n",
       "      <td>0.282353</td>\n",
       "      <td>0.071425</td>\n",
       "      <td>0.341843</td>\n",
       "      <td>0.156064</td>\n",
       "      <td>3395.380184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>214.163767</td>\n",
       "      <td>2.114037</td>\n",
       "      <td>471.107508</td>\n",
       "      <td>3.520708</td>\n",
       "      <td>5.231231</td>\n",
       "      <td>3.264816</td>\n",
       "      <td>11.332017</td>\n",
       "      <td>3.855141</td>\n",
       "      <td>8.309434</td>\n",
       "      <td>4.107855</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071315</td>\n",
       "      <td>0.247786</td>\n",
       "      <td>0.127726</td>\n",
       "      <td>0.290290</td>\n",
       "      <td>0.095373</td>\n",
       "      <td>0.324247</td>\n",
       "      <td>0.265450</td>\n",
       "      <td>0.188791</td>\n",
       "      <td>0.226294</td>\n",
       "      <td>11626.950749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>164.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>246.000000</td>\n",
       "      <td>0.470870</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.625739</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>-0.328383</td>\n",
       "      <td>-0.700000</td>\n",
       "      <td>-0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>946.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>339.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>409.000000</td>\n",
       "      <td>0.539226</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.690476</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>-0.253333</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1400.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>542.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>716.000000</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.754630</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.186905</td>\n",
       "      <td>-0.300000</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>2800.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>731.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>8474.000000</td>\n",
       "      <td>701.000000</td>\n",
       "      <td>1042.000000</td>\n",
       "      <td>650.000000</td>\n",
       "      <td>304.000000</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>843300.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          timedelta  n_tokens_title  n_tokens_content  n_unique_tokens  \\\n",
       "count  39644.000000    39644.000000      39644.000000     39644.000000   \n",
       "mean     354.530471       10.398749        546.514731         0.548216   \n",
       "std      214.163767        2.114037        471.107508         3.520708   \n",
       "min        8.000000        2.000000          0.000000         0.000000   \n",
       "25%      164.000000        9.000000        246.000000         0.470870   \n",
       "50%      339.000000       10.000000        409.000000         0.539226   \n",
       "75%      542.000000       12.000000        716.000000         0.608696   \n",
       "max      731.000000       23.000000       8474.000000       701.000000   \n",
       "\n",
       "       n_non_stop_words  n_non_stop_unique_tokens     num_hrefs  \\\n",
       "count      39644.000000              39644.000000  39644.000000   \n",
       "mean           0.996469                  0.689175     10.883690   \n",
       "std            5.231231                  3.264816     11.332017   \n",
       "min            0.000000                  0.000000      0.000000   \n",
       "25%            1.000000                  0.625739      4.000000   \n",
       "50%            1.000000                  0.690476      8.000000   \n",
       "75%            1.000000                  0.754630     14.000000   \n",
       "max         1042.000000                650.000000    304.000000   \n",
       "\n",
       "       num_self_hrefs      num_imgs    num_videos  ...  min_positive_polarity  \\\n",
       "count    39644.000000  39644.000000  39644.000000  ...           39644.000000   \n",
       "mean         3.293638      4.544143      1.249874  ...               0.095446   \n",
       "std          3.855141      8.309434      4.107855  ...               0.071315   \n",
       "min          0.000000      0.000000      0.000000  ...               0.000000   \n",
       "25%          1.000000      1.000000      0.000000  ...               0.050000   \n",
       "50%          3.000000      1.000000      0.000000  ...               0.100000   \n",
       "75%          4.000000      4.000000      1.000000  ...               0.100000   \n",
       "max        116.000000    128.000000     91.000000  ...               1.000000   \n",
       "\n",
       "       max_positive_polarity  avg_negative_polarity  min_negative_polarity  \\\n",
       "count           39644.000000           39644.000000           39644.000000   \n",
       "mean                0.756728              -0.259524              -0.521944   \n",
       "std                 0.247786               0.127726               0.290290   \n",
       "min                 0.000000              -1.000000              -1.000000   \n",
       "25%                 0.600000              -0.328383              -0.700000   \n",
       "50%                 0.800000              -0.253333              -0.500000   \n",
       "75%                 1.000000              -0.186905              -0.300000   \n",
       "max                 1.000000               0.000000               0.000000   \n",
       "\n",
       "       max_negative_polarity  title_subjectivity  title_sentiment_polarity  \\\n",
       "count           39644.000000        39644.000000              39644.000000   \n",
       "mean               -0.107500            0.282353                  0.071425   \n",
       "std                 0.095373            0.324247                  0.265450   \n",
       "min                -1.000000            0.000000                 -1.000000   \n",
       "25%                -0.125000            0.000000                  0.000000   \n",
       "50%                -0.100000            0.150000                  0.000000   \n",
       "75%                -0.050000            0.500000                  0.150000   \n",
       "max                 0.000000            1.000000                  1.000000   \n",
       "\n",
       "       abs_title_subjectivity  abs_title_sentiment_polarity         shares  \n",
       "count            39644.000000                  39644.000000   39644.000000  \n",
       "mean                 0.341843                      0.156064    3395.380184  \n",
       "std                  0.188791                      0.226294   11626.950749  \n",
       "min                  0.000000                      0.000000       1.000000  \n",
       "25%                  0.166667                      0.000000     946.000000  \n",
       "50%                  0.500000                      0.000000    1400.000000  \n",
       "75%                  0.500000                      0.250000    2800.000000  \n",
       "max                  0.500000                      1.000000  843300.000000  \n",
       "\n",
       "[8 rows x 60 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data types of the variables\n",
    "news_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create binary variable popularity based on number of shares:\n",
    "news_data.loc[news_data.shares >= 1400,'popular'] = 1\n",
    "news_data.loc[news_data.shares < 1400,'popular'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate target and training features\n",
    "X = news_data.drop(['popular','shares','url'],axis = 1)\n",
    "y = news_data['popular']\n",
    "y = pd.Series(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: Data pre-processing\n",
    "Since features are on different scales, standardizing them by subtracting means and dividing by the standard deviations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Separate numeric variables from the categorical\n",
    "\n",
    "# X_cat = X[['data_channel_is_lifestyle','data_channel_is_entertainment','data_channel_is_bus','data_channel_is_socmed',\n",
    "#           'data_channel_is_tech','data_channel_is_world','weekday_is_monday','weekday_is_tuesday','weekday_is_wednesday',\n",
    "#           'weekday_is_thursday','weekday_is_friday','weekday_is_saturday','weekday_is_sunday','is_weekend']]\n",
    "\n",
    "# X_num = X[X.columns.difference(X_cat.columns)]\n",
    "\n",
    "# # X_num = X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Min max scaling\n",
    "# scaler = preprocessing.MinMaxScaler()\n",
    "# X_sc = scaler.fit_transform(X_num, y=y)\n",
    "# X_sc = pd.DataFrame(X_sc, index=X_num.index, columns=X_num.columns)\n",
    "\n",
    "# X_sc = pd.concat([X_sc, X_cat], axis = 1)\n",
    "\n",
    "# # sc_y = StandardScaler()\n",
    "# y = np.array(y).reshape(-1,1)\n",
    "# y_sc = scaler.fit_transform(y)\n",
    "# y_sc = y.flatten()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Split into train, test and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                   test_size = 0.3,\n",
    "                                                   random_state = 123)\n",
    "\n",
    "#It's good practice to stratify your sample by the target variable. \n",
    "#This will ensure your training set looks similar to your test set, making your evaluation metrics more reliable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use min-max scaling to scale the data\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scale = scaler.fit_transform(X_train)\n",
    "X_test_scale = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training data into testing and validation\n",
    "\n",
    "X_train_sub, X_validation_sub, y_train_sub, y_validation_sub = train_test_split(X_train_scale, y_train, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.01\n",
      "Accuracy score (training): 0.762\n",
      "Accuracy score (validation): 0.669\n",
      "\n",
      "Learning rate:  0.05\n",
      "Accuracy score (training): 0.899\n",
      "Accuracy score (validation): 0.667\n",
      "\n",
      "Learning rate:  0.1\n",
      "Accuracy score (training): 0.976\n",
      "Accuracy score (validation): 0.662\n",
      "\n",
      "Learning rate:  0.25\n",
      "Accuracy score (training): 1.000\n",
      "Accuracy score (validation): 0.652\n",
      "\n",
      "Learning rate:  0.5\n",
      "Accuracy score (training): 1.000\n",
      "Accuracy score (validation): 0.648\n",
      "\n",
      "Learning rate:  0.75\n",
      "Accuracy score (training): 1.000\n",
      "Accuracy score (validation): 0.635\n",
      "\n",
      "Learning rate:  1\n",
      "Accuracy score (training): 1.000\n",
      "Accuracy score (validation): 0.627\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "learning_rates = [0.01,0.05, 0.1, 0.25, 0.5, 0.75, 1]\n",
    "for learning_rate in learning_rates:\n",
    "    gb = GradientBoostingClassifier(n_estimators=500, learning_rate = learning_rate, max_features=40, max_depth = 6, random_state = 0)\n",
    "    gb.fit(X_train_sub, y_train_sub)\n",
    "    print(\"Learning rate: \", learning_rate)\n",
    "    print(\"Accuracy score (training): {0:.3f}\".format(gb.score(X_train_sub, y_train_sub)))\n",
    "    print(\"Accuracy score (validation): {0:.3f}\".format(gb.score(X_validation_sub, y_validation_sub)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[1970 1285]\n",
      " [1059 2624]]\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.65      0.61      0.63      3255\n",
      "         1.0       0.67      0.71      0.69      3683\n",
      "\n",
      "    accuracy                           0.66      6938\n",
      "   macro avg       0.66      0.66      0.66      6938\n",
      "weighted avg       0.66      0.66      0.66      6938\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using learning rate 1:\n",
    "# Output confusion matrix and classification report of Gradient Boosting algorithm on validation set\n",
    "\n",
    "gb = GradientBoostingClassifier(n_estimators=500, learning_rate = 0.1, max_features=40, max_depth = 6, random_state = 0)\n",
    "gb.fit(X_train_sub, y_train_sub)\n",
    "predictions = gb.predict(X_validation_sub)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_validation_sub, predictions))\n",
    "print()\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_validation_sub, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "del auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under ROC curve = 0.72\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import auc\n",
    "# ROC curve and Area-Under-Curve (AUC)\n",
    "\n",
    "y_pred_proba = gb.predict_proba(X_validation_sub)[::,1]\n",
    "y_scores_gb = gb.decision_function(X_validation_sub)\n",
    "\n",
    "fpr_gb, tpr_gb, _ = roc_curve(y_validation_sub, y_scores_gb)\n",
    "\n",
    "roc_auc_gb = auc(fpr_gb, tpr_gb)\n",
    "\n",
    "plt.plot(fpr_gb,tpr_gb,label=\"data 1, auc=\"+str(roc_auc_gb))\n",
    "\n",
    "print(\"Area under ROC curve = {:0.2f}\".format(roc_auc_gb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other Classifiers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n",
      "Training Accuracy=61.0 %\n",
      "Testing Accuracy=48.0 %\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(max_iter=1000)\n",
    "clf_lr=lr.fit(X_train,y_train)\n",
    "\n",
    "lr_train_acc = clf_lr.score(X_train,y_train.ravel())\n",
    "lr_train_acc = str(lr_train_acc.round(2) * 100) + ' %'\n",
    "\n",
    "\n",
    "lr_test_acc = clf_lr.score(X_validation_sub,y_validation_sub.ravel())\n",
    "lr_test_acc = str(lr_test_acc.round(2) * 100) + ' %'\n",
    "\n",
    "print('Logistic Regression:')\n",
    "print('Training Accuracy='+ lr_train_acc)\n",
    "print('Testing Accuracy='+ lr_test_acc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:\n",
      "Training Accuracy=100.0 %\n",
      "Testing Accuracy=55.00000000000001 %\n"
     ]
    }
   ],
   "source": [
    "rf=RandomForestClassifier(n_estimators=100,n_jobs=-1)\n",
    "clf_rf=rf.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "rf_train_acc = clf_rf.score(X_train,y_train)\n",
    "rf_train_acc = str(rf_train_acc.round(2) * 100) + ' %'\n",
    "\n",
    "\n",
    "rf_test_acc = clf_rf.score(X_validation_sub,y_validation_sub.ravel())\n",
    "rf_test_acc = str(rf_test_acc.round(2) * 100) + ' %'\n",
    "\n",
    "print('Random Forest:')\n",
    "print('Training Accuracy='+ rf_train_acc)\n",
    "print('Testing Accuracy='+ rf_test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
